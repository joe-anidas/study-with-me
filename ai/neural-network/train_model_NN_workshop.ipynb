{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "25fZh19_Csar"
      },
      "source": [
        "!git clone https://github.com/Jaish19/Artificial-Intelligence.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0hOhMiaEsMru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgBR5tyJCvr8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d7fd7a-38f7-4c3b-b64c-4c915bcedc0f"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import joblib\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# Disable some pandas warnings\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/Artificial-Intelligence/Neural Network Model/house_data.csv\")\n",
        "\n",
        "# Prepare features & target\n",
        "X = df[[\"sq_feet\", \"num_bedrooms\", \"num_bathrooms\"]]\n",
        "y = df[[\"sale_price\"]]\n",
        "\n",
        "# Scale inputs & outputs\n",
        "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X[X.columns] = X_scaler.fit_transform(X[X.columns])\n",
        "y[y.columns] = y_scaler.fit_transform(y[y.columns])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(3,)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer='adam'   # faster & usually better than SGD\n",
        ")\n",
        "\n",
        "# Train longer with reasonable batch size\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, shuffle=True, verbose=2)\n",
        "\n",
        "# Ensure save directory exists\n",
        "save_dir = \"/content/Artificial-Intelligence/Neural Network Model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save scalers\n",
        "joblib.dump(X_scaler, os.path.join(save_dir, \"X_scaler.pkl\"))\n",
        "joblib.dump(y_scaler, os.path.join(save_dir, \"y_scaler.pkl\"))\n",
        "\n",
        "# Save model in recommended format\n",
        "model.save(os.path.join(save_dir, \"house_value_model.keras\"))\n",
        "\n",
        "# Evaluate\n",
        "print(\"Model training results:\")\n",
        "predictions_train = model.predict(X_train, verbose=0)\n",
        "mse_train = mean_absolute_error(\n",
        "    y_scaler.inverse_transform(predictions_train),\n",
        "    y_scaler.inverse_transform(y_train)\n",
        ")\n",
        "print(f\" - Training Set Error: {mse_train:.2f}\")\n",
        "\n",
        "predictions_test = model.predict(X_test, verbose=0)\n",
        "mse_test = mean_absolute_error(\n",
        "    y_scaler.inverse_transform(predictions_test),\n",
        "    y_scaler.inverse_transform(y_test)\n",
        ")\n",
        "print(f\" - Test Set Error: {mse_test:.2f}\")\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "235/235 - 2s - 7ms/step - loss: 0.0065\n",
            "Epoch 2/50\n",
            "235/235 - 1s - 4ms/step - loss: 3.5026e-04\n",
            "Epoch 3/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5518e-04\n",
            "Epoch 4/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6009e-04\n",
            "Epoch 5/50\n",
            "235/235 - 1s - 4ms/step - loss: 3.6011e-04\n",
            "Epoch 6/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6226e-04\n",
            "Epoch 7/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6516e-04\n",
            "Epoch 8/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.7649e-04\n",
            "Epoch 9/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.8485e-04\n",
            "Epoch 10/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.9348e-04\n",
            "Epoch 11/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.9538e-04\n",
            "Epoch 12/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.8599e-04\n",
            "Epoch 13/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.8649e-04\n",
            "Epoch 14/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.8625e-04\n",
            "Epoch 15/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.8230e-04\n",
            "Epoch 16/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.8283e-04\n",
            "Epoch 17/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.8630e-04\n",
            "Epoch 18/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.7760e-04\n",
            "Epoch 19/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.7752e-04\n",
            "Epoch 20/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.7715e-04\n",
            "Epoch 21/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.7378e-04\n",
            "Epoch 22/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.7437e-04\n",
            "Epoch 23/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.7232e-04\n",
            "Epoch 24/50\n",
            "235/235 - 1s - 5ms/step - loss: 3.7225e-04\n",
            "Epoch 25/50\n",
            "235/235 - 1s - 4ms/step - loss: 3.6974e-04\n",
            "Epoch 26/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6971e-04\n",
            "Epoch 27/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6761e-04\n",
            "Epoch 28/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6725e-04\n",
            "Epoch 29/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6520e-04\n",
            "Epoch 30/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6586e-04\n",
            "Epoch 31/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6420e-04\n",
            "Epoch 32/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6313e-04\n",
            "Epoch 33/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6324e-04\n",
            "Epoch 34/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6266e-04\n",
            "Epoch 35/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6258e-04\n",
            "Epoch 36/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6139e-04\n",
            "Epoch 37/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6037e-04\n",
            "Epoch 38/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6044e-04\n",
            "Epoch 39/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.6038e-04\n",
            "Epoch 40/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6028e-04\n",
            "Epoch 41/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6047e-04\n",
            "Epoch 42/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5983e-04\n",
            "Epoch 43/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.6000e-04\n",
            "Epoch 44/50\n",
            "235/235 - 1s - 5ms/step - loss: 3.5996e-04\n",
            "Epoch 45/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.5995e-04\n",
            "Epoch 46/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5957e-04\n",
            "Epoch 47/50\n",
            "235/235 - 0s - 2ms/step - loss: 3.5936e-04\n",
            "Epoch 48/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5921e-04\n",
            "Epoch 49/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5949e-04\n",
            "Epoch 50/50\n",
            "235/235 - 1s - 3ms/step - loss: 3.5932e-04\n",
            "Model training results:\n",
            " - Training Set Error: 9446.96\n",
            " - Test Set Error: 9652.22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
        "import joblib\n",
        "import tensorflow as tf\n",
        "\n",
        "# =========================\n",
        "# 1. Set Seeds (Reproducibility)\n",
        "# =========================\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "# =========================\n",
        "# 2. Load dataset\n",
        "# =========================\n",
        "df = pd.read_csv(\"/content/Artificial-Intelligence/Neural Network Model/house_data.csv\")\n",
        "\n",
        "# Prepare features & target\n",
        "X = df[[\"sq_feet\", \"num_bedrooms\", \"num_bathrooms\"]]\n",
        "y = df[[\"sale_price\"]]\n",
        "\n",
        "# =========================\n",
        "# 3. Scale inputs & outputs\n",
        "# =========================\n",
        "X_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "y_scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X[X.columns] = X_scaler.fit_transform(X[X.columns])\n",
        "y[y.columns] = y_scaler.fit_transform(y[y.columns])\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=seed\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 4. Build Model (with regularization)\n",
        "# =========================\n",
        "model = Sequential([\n",
        "    Input(shape=(3,)),\n",
        "    Dense(64, activation='relu', kernel_regularizer='l2'),\n",
        "    Dropout(0.2),\n",
        "    Dense(128, activation='relu', kernel_regularizer='l2'),\n",
        "    Dropout(0.2),\n",
        "    Dense(64, activation='relu', kernel_regularizer='l2'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Compile with Adam optimizer and custom LR\n",
        "model.compile(\n",
        "    loss='mean_squared_error',\n",
        "    optimizer=Adam(learning_rate=0.001)\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 5. Add Early Stopping\n",
        "# =========================\n",
        "early_stop = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 6. Train the Model\n",
        "# =========================\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# 7. Save Model & Scalers\n",
        "# =========================\n",
        "save_dir = \"/content/Artificial-Intelligence/Neural Network Model\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "joblib.dump(X_scaler, os.path.join(save_dir, \"X_scaler.pkl\"))\n",
        "joblib.dump(y_scaler, os.path.join(save_dir, \"y_scaler.pkl\"))\n",
        "model.save(os.path.join(save_dir, \"house_value_model.keras\"))\n",
        "\n",
        "# =========================\n",
        "# 8. Evaluate Model\n",
        "# =========================\n",
        "print(\"\\nModel training results:\")\n",
        "\n",
        "# Training predictions\n",
        "predictions_train = model.predict(X_train, verbose=0)\n",
        "mse_train = mean_absolute_error(\n",
        "    y_scaler.inverse_transform(y_train),\n",
        "    y_scaler.inverse_transform(predictions_train)\n",
        ")\n",
        "mape_train = mean_absolute_percentage_error(\n",
        "    y_scaler.inverse_transform(y_train),\n",
        "    y_scaler.inverse_transform(predictions_train)\n",
        ")\n",
        "print(f\" - Training Set Error (MAE): {mse_train:.2f}\")\n",
        "print(f\" - Training Set Error (MAPE): {mape_train*100:.2f}%\")\n",
        "\n",
        "# Test predictions\n",
        "predictions_test = model.predict(X_test, verbose=0)\n",
        "mse_test = mean_absolute_error(\n",
        "    y_scaler.inverse_transform(y_test),\n",
        "    y_scaler.inverse_transform(predictions_test)\n",
        ")\n",
        "mape_test = mean_absolute_percentage_error(\n",
        "    y_scaler.inverse_transform(y_test),\n",
        "    y_scaler.inverse_transform(predictions_test)\n",
        ")\n",
        "print(f\" - Test Set Error (MAE): {mse_test:.2f}\")\n",
        "print(f\" - Test Set Error (MAPE): {mape_test*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "vUwNCafNsBt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test the trained model"
      ],
      "metadata": {
        "id": "WBvVAX2V0d1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load trained model (no compile needed for prediction)\n",
        "model = keras.models.load_model(\n",
        "    '/content/Artificial-Intelligence/Neural Network Model/house_value_model.h5',\n",
        "    compile=False\n",
        ")\n",
        "\n",
        "# Load scalers\n",
        "X_scaler = joblib.load('/content/Artificial-Intelligence/Neural Network Model/X_scaler.pkl')\n",
        "y_scaler = joblib.load('/content/Artificial-Intelligence/Neural Network Model/y_scaler.pkl')\n",
        "\n",
        "# Define house\n",
        "house_1 = [800, 2, 2]  # sq_feet, bedrooms, bathrooms\n",
        "homes = [house_1]\n",
        "\n",
        "# Convert to DataFrame with column names (to match training)\n",
        "homes_df = pd.DataFrame(homes, columns=[\"sq_feet\", \"num_bedrooms\", \"num_bathrooms\"])\n",
        "\n",
        "# Scale input\n",
        "scaled_home_data = X_scaler.transform(homes_df)\n",
        "\n",
        "# Predict\n",
        "home_values = model.predict(scaled_home_data, verbose=0)\n",
        "\n",
        "# Unscale output\n",
        "unscaled_home_values = y_scaler.inverse_transform(home_values)\n",
        "predicted_value = unscaled_home_values[0][0]\n",
        "\n",
        "# Print results\n",
        "print(\"House details:\")\n",
        "print(f\"- {house_1[0]} sq feet\")\n",
        "print(f\"- {house_1[1]} bedrooms\")\n",
        "print(f\"- {house_1[2]} bathrooms\")\n",
        "print(f\"Estimated value: ${predicted_value:,.2f}\")\n"
      ],
      "metadata": {
        "id": "A8mcoapW0LpW",
        "outputId": "e554755c-f52b-41ce-cf31-ecfc022ab48c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "House details:\n",
            "- 800 sq feet\n",
            "- 2 bedrooms\n",
            "- 2 bathrooms\n",
            "Estimated value: $183,724.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oO-EJR7c0ZXW"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}